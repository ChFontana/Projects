class MachineLearning:
    def __init__(self):
        pass

    def definition():
        print(
            """
        Machine learning is the study of computer algorithms that improve automatically through experience. 
        It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, 
        known as "training data", in order to make predictions or decisions without being explicitly programmed to do so. 
        Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, 
        where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.
        """
        )

    def methods():
        print(
            """
        There are 3 main types of machine learning algorithms:
        1. Supervised learning
        2. Unsupervised learning
        3. Reinforcement learning
        """
        )

    def supervised_learning():
        print(
            """
        Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. 
        It infers a function from labeled training data consisting of a set of training examples. 
        In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). 
        A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. 
        An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. 
        This requires the learning algorithm to generalize from the training data to unseen situations in a "reasonable" way (see inductive bias).
        """
        )

    def unsupervised_learning():
        print(
            """
        Unsupervised learning is a type of machine learning algorithm used to draw inferences from datasets consisting of input data without labeled responses. 
        The most common unsupervised learning method is cluster analysis, which is used for exploratory data analysis to find hidden patterns or grouping in data. 
        The clusters are modeled using a measure of similarity which is defined upon metrics such as Euclidean or probabilistic distance.
        """
        )

    def reinforcement_learning():
        print(
            """
        Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. 
        Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.
        """
        )

    def supervised_learning_algorithms():
        print(
            """
        There are 2 main types of supervised learning algorithms:
        1. Classification
        2. Regression
        """
        )

    def classification():
        print(
            """
        In machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs,
        on the basis of a training set of data containing observations (or instances) whose category membership is known.
        """
        )

    def regression():
        print(
            """
        In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships between a dependent variable (often called the 'outcome variable') and one or more independent variables (often called 'predictors', 'covariates', or 'features').
        """
        )

    def unsupervised_learning_algorithms():
        print(
            """
        There are 2 main types of unsupervised learning algorithms:
        1. Clustering
        2. Association
        """
        )

    def clustering():
        print(
            """
        Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) 
        to each other than to those in other groups (clusters). It is a main task of exploratory data mining, and a common technique for statistical data analysis, 
        used in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.
        """
        )

    def association():
        print(
            """
        Association rule learning is a rule-based machine learning method for discovering interesting relations between variables in large databases. 
        It is intended to identify strong rules discovered in databases using some measures of interestingness.
        """
        )

    def reinforcement_learning_algorithms():
        print(
            """
        There are 2 main types of reinforcement learning algorithms:
        1. Value-based
        2. Policy-based
        """
        )

    def value_based():
        print(
            """
        Value-based methods directly estimate the optimal value function or optimal policy, without having to learn the intermediate representation (policy or value function).
        """
        )

    def policy_based():
        print(
            """
        Policy-based methods directly learn the optimal policy, without having to learn the intermediate representation (policy or value function).
        """
        )

    def machine_learning_algorithms():
        print(
            """
        There are 2 main types of machine learning algorithms:
        1. Batch learning
        2. Online learning
        """
        )

    def batch_learning():
        print(
            """
        Batch learning is a machine learning technique in which a model is trained using all of the training data at once. 
        It is the traditional machine learning approach. 
        Batch learning is still used today, but it is being supplanted by online learning, which is more suitable for large datasets.
        """
        )

    def online_learning():
        print(
            """
        Online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update our best predictor for future data at each step, 
        as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once. 
        Online learning is a common technique used in areas of machine learning where it is computationally infeasible to train over the entire dataset, 
        requiring the need of out-of-core algorithms. 
        Online learning is closely related to the fields of data stream mining and incremental learning.
        """
        )

    def machine_learning_models():
        print(
            """
        There are 2 main types of machine learning models:
        1. Discriminative
        2. Generative
        """
        )

    def discriminative():
        print(
            """
        Discriminative models are a class of models used in machine learning for modeling the dependence of an unobserved variable y on an observed variable x. 
        They are typically used for modeling conditional probability distributions and are closely related to the field of supervised learning, 
        where an algorithm is tasked with learning a model from training data.
        """
        )

    def generative():
        print(
            """
        Generative models are a class of models used in machine learning for modeling the distribution of observed data, 
        typically conditional on some other data. 
        They are typically used for modeling probability distributions and generating new data from existing data.
        """
        )


class Statistics:
    def __init__(self) -> None:
        pass

    def definition():
        print(
            """
        Statistics is the discipline that concerns the collection, organization, analysis, interpretation, and presentation of data. 
        In applying statistics to a scientific, industrial, or social problem, it is conventional to begin with a statistical population or a statistical model to be studied. 
        Populations can be diverse groups of people or objects such as "all people living in a country" or "every atom composing a crystal". 
        Statistics deals with every aspect of data, including the planning of data collection in terms of the design of surveys and experiments.
        """
        )

    def types_of_statistics():
        print(
            """
        There are 2 main types of statistics:
        1. Descriptive statistics
        2. Inferential statistics
        """
        )

    def descriptive_statistics():
        print(
            """
        Descriptive statistics is the discipline of quantitatively describing the main features of a collection of data. 
        Descriptive statistics are distinguished from inferential statistics (or inductive statistics), in that descriptive statistics aim to summarize a sample, 
        rather than use the data to learn about the population that the sample of data is thought to represent. 
        This generally means that descriptive statistics, unlike inferential statistics, are not developed on the basis of probability theory.
        """
        )

    def inferential_statistics():
        print(
            """
        Inferential statistics is the process of using data analysis to deduce properties of an underlying distribution of probability. 
        Inferential statistical analysis infers properties of a population, for example by testing hypotheses and deriving estimates. 
        It is assumed that the observed data set is sampled from a larger population.
        """
        )

    def types_of_data():
        print(
            """
        There are 2 main types of data:
        1. Quantitative data
        2. Qualitative data
        """
        )

    def quantitative_data():
        print(
            """
        Quantitative data is information about quantities, and therefore numbers, and therefore measurable. 
        Quantitative data is based on quantities obtained using a quantifiable measurement process. 
        In statistics, quantitative data is numerical and acquired through counting or measuring and contrasted with qualitative data sets, 
        which describe attributes of objects but do not contain numbers.
        """
        )

    def qualitative_data():
        print(
            """
        Qualitative data is information about qualities; information that can't actually be measured. 
        Some examples of qualitative data are the softness of your skin, the grace with which you run, and the color of your eyes. 
        However, try telling Photoshop you can't measure color with numbers!
        """
        )

    def types_of_variables():
        print(
            """
        There are 2 main types of variables:
        1. Discrete variable
        2. Continuous variable
        """
        )

    def discrete_variable():
        print(
            """
        A discrete variable is a variable whose value is obtained by counting. 
        A discrete variable can be numeric or non-numeric. 
        A discrete variable is always numeric. 
        Examples of discrete variables include:
        1. The number of eggs that a hen lays
        2. The number of students who attend class every day
        3. The number of phone calls that you receive
        """
        )

    def continuous_variable():
        print(
            """
        A continuous variable is a variable whose value is obtained by measuring. 
        A continuous variable can be numeric or non-numeric. 
        A continuous variable is always numeric. 
        Examples of continuous variables include:
        1. The height of a person
        2. The weight of a person
        3. The temperature in a room
        """
        )

    def types_of_distributions():
        print(
            """
        There are 2 main types of distributions:
        1. Discrete distribution
        2. Continuous distribution
        """
        )

    def discrete_distribution():
        print(
            """
        A discrete distribution is a statistical distribution that shows the probabilities of outcomes with finite values. 
        A discrete distribution is a statistical distribution that shows the probabilities of outcomes with finite values. 
        For example, a coin toss would be a discrete distribution because the outcome can be only two values: heads or tails. 
        A die roll would be a discrete distribution because the outcomes can only be the numbers 1 through 6.
        """
        )

    def continuous_distribution():
        print(
            """
        A continuous distribution is a statistical distribution that has infinite possible values. 
        Continuous distributions are encountered in many scientific and engineering areas, including physics, chemistry, biology, engineering, finance, and economics. 
        The normal distribution, also called the Gaussian distribution, is a continuous distribution that is very important in science and engineering.
        """
        )

    def bayes_theorem():
        print(
            """
        Bayes' theorem is a formula that describes how to update the probabilities of hypotheses when given evidence. 
        It follows simply from the axioms of conditional probability, but can be used to powerfully reason about a wide range of problems involving belief updates.
        """
        )

    def bayes_theorem_formula():
        print(
            """
        P(A|B) = (P(B|A) * P(A)) / P(B)
        """
        )

    def bayes_theorem_formula_explanation():
        print(
            """
        P(A|B) = Posterior probability
        P(B|A) = Likelihood
        P(A) = Prior probability
        P(B) = Marginal likelihood
        """
        )

    def bayes_theorem_example():
        print(
            """
        Let's say we have a test to determine if a person has a certain disease. 
        The test is 99% accurate, meaning that the probability of a false positive is 1%. 
        The probability of a false negative is zero. 
        We also know that 1 in 10,000 people have this disease. 
        If we test a person and they test positive, what is the probability that they actually have the disease?
        """
        )

    def normal_tendency():
        print(
            """
        Normal tendency is the tendency of a data set to cluster around a central value. 
        This central value is called the mean or the average. 
        The mean is the sum of all the values in the data set divided by the number of values in the data set. 
        The mean is also called the arithmetic mean or the average.
        """
        )

    def normal_distribution():
        print(
            """
        A normal distribution is a type of probability distribution that is symmetric about the mean. 
        The normal distribution is a continuous probability distribution. 
        A normal distribution is the proper term for a probability bell curve.
        """
        )
