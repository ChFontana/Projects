{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "                                              0.0/143.0 kB ? eta -:--:--\n",
      "     --------                                30.7/143.0 kB 1.4 MB/s eta 0:00:01\n",
      "     --------                                30.7/143.0 kB 1.4 MB/s eta 0:00:01\n",
      "     ----------------------------         112.6/143.0 kB 939.4 kB/s eta 0:00:01\n",
      "     ----------------------------         112.6/143.0 kB 939.4 kB/s eta 0:00:01\n",
      "     ----------------------------         112.6/143.0 kB 939.4 kB/s eta 0:00:01\n",
      "     ------------------------------------ 143.0/143.0 kB 567.3 kB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (pyproject.toml): started\n",
      "  Building wheel for bs4 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1266 sha256=947fe9dfdd20c383c5bf4223e9724cad16f395750093b0fb066af73c02454670\n",
      "  Stored in directory: c:\\users\\cfont\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\d4\\c8\\5b\\b5be9c20e5e4503d04a6eac8a3cd5c2393505c29f02bea0960\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.12.2 bs4-0.0.1 soupsieve-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import urllib\n",
    "import json\n",
    "import selenium\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.service import Service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "file created\n"
     ]
    }
   ],
   "source": [
    "service = Service(executable_path='C:/ProgramData/Microsoft/Windows/Start Menu/Programs/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "def openbrowser(locid, key):\n",
    "    driver.wait = WebDriverWait(driver, 5)\n",
    "    driver.maximize_window()\n",
    "    words = key.split()\n",
    "    txt =''    \n",
    "    for w in words:\n",
    "        txt +=(w+'+')\n",
    "    #print (txt)\n",
    "    driver.get(\"https://www.glassdoor.co.in/Job/jobs.htm?suggestCount=0&suggestChosen=true&clickSource=searchBtn&typedKeyword={}\\\n",
    "               &sc.keyword={}&locT=C&locId={}&jobType=fulltime&fromAge=1&radius=6&cityId=-1&minRating=0.0&industryId=-1\\\n",
    "               &sgocId=-1&companyId=-1&employerSizes=0&applicationType=0&remoteWorkType=0\".format(txt[:-1],txt[:-1], locid))\n",
    "    return driver\n",
    "\n",
    "def geturl(driver):\n",
    "    url = set()\n",
    "    while True:\n",
    "        print(len(url))\n",
    "        if len(url)>=20:\n",
    "            break\n",
    "        soup1 = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        main = soup1.find_all(\"li\",{\"class\":\"jl\"})\n",
    "        \n",
    "        for m in main:\n",
    "            url.add('https://www.glassdoor.co.in{}'.format(m.find('a')['href']))       \n",
    "        try:\n",
    "            next_element = soup1.find(\"li\", {\"class\": \"next\"})\n",
    "            try:\n",
    "                next_exist = next_element.find('a')\n",
    "            except AttributeError:\n",
    "                driver.quit()\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                driver.quit()\n",
    "                break\n",
    "            if next_exist:\n",
    "    \n",
    "                driver.find_element_by_class_name(\"next\").click()\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                driver.quit()\n",
    "                break\n",
    "        except ElementClickInterceptedException:\n",
    "            pass\n",
    "        \n",
    "    return list(url)\n",
    "\n",
    "x =openbrowser(locid =4477468, key='\"software testing\"')\n",
    "with open('url_software_testing_loc_bangalore.json','w') as f:\n",
    "    json.dump(geturl(driver),f, indent = 4)\n",
    "    print(\"file created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'url_software_testing_loc_bangalore.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39murl_software_testing_loc_bangalore.json\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     url \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m      3\u001b[0m data \u001b[39m=\u001b[39m{}    \n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'url_software_testing_loc_bangalore.json'"
     ]
    }
   ],
   "source": [
    "with open('url_software_testing_loc_bangalore.json','r') as f:\n",
    "    url = json.load(f)\n",
    "data ={}    \n",
    "i = 1\n",
    "jd_df = pd.DataFrame()\n",
    "\n",
    "service = Service(executable_path='C:/ProgramData/Microsoft/Windows/Start Menu/Programs/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "for u in tqdm(url):\n",
    "    driver.wait = WebDriverWait(driver, 2)\n",
    "    driver.maximize_window()\n",
    "    driver.get(u)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    try:\n",
    "       \n",
    "        header = soup.find(\"div\",{\"class\":\"header cell info\"})\n",
    "        position = driver.find_element_by_tag_name('h2').text\n",
    "        company = driver.find_element_by_xpath(\"//span[@class='strong ib']\").text\n",
    "        location = driver.find_element_by_xpath(\"//span[@class='subtle ib']\").text\n",
    "        jd_temp = driver.find_element_by_id(\"JobDescriptionContainer\")\n",
    "        jd = jd_temp.text\n",
    "        info = soup.find_all(\"infoEntity\")\n",
    "    except IndexError:\n",
    "        print('IndexError: list index out of range')\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    data[i] = {\n",
    "        'url' :u,\n",
    "        'Position':position,\n",
    "        'Company': company,\n",
    "        'Location' :location,\n",
    "        'Job_Description' :jd\n",
    "    }\n",
    "    i+=1     \n",
    "driver.quit()\n",
    "jd_df = pd.DataFrame(data)\n",
    "jd = jd_df.transpose()\n",
    "\n",
    "jd = jd[['url','Position','Company','Location','Job_Description']]\n",
    "jd.to_csv('jd_software_testing_banglore.csv')\n",
    "print('file created')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
